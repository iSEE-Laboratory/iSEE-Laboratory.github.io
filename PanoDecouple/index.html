<!DOCTYPE html>
<html>
<head>

  <meta charset="utf-8">
  <meta name="description"
        content="Panorama Generation From NFoV Image Done Right">
  <meta name="keywords" content="Evaluation, Text-to-Panorama, Stable Diffusion, AIGC, Image Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Panorama Generation From NFoV Image Done Right</title>

<!--   Global site tag (gtag.js) - Google Analytics-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y5ZVQZ7NHC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-Y5ZVQZ7NHC');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">

  <link rel="stylesheet" href="./assets/panodecouple/css/bulma.min.css">
  <link rel="stylesheet" href="./assets/panodecouple/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./assets/panodecouple/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./assets/panodecouple/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./assets/panodecouple/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./assets/panodecouple/js/fontawesome.all.min.js"></script>
  <script src="./assets/panodecouple/js/bulma-carousel.min.js"></script>
  <script src="./assets/panodecouple/js/bulma-slider.min.js"></script>
  <script src="./assets/panodecouple/js/index.js"></script>
</head>
<body>

<!-- title -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span style="color:#B9770E; font-weight: bold; font-style: italic">PanoDecouple</span><br> Panorama Generation From NFoV Image Done Right</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">CVPR 2025</span>
        </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">

              <span class="author-block">
                  <a href="https://zhengdian1.github.io" target="_blank">Dian Zheng</a><sup>1*</sup>,
              </span>
              <span class="author-block">
                  <a href="https://chengzhag.github.io" target="_blank">Cheng Zhang</a><sup>2</sup>,
              </span>
              <span class="author-block">
                  <a href="https://dravenalg.github.io" target="_blank">Xiao-Ming Wu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                Cao Li<sup>3&#8224</sup>,
              </span>
              <br>
              <span class="author-block">
                  Chengfei Lv<sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://isee-ai.cn/~hujianfang" target="_blank">Jian-Fang Hu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.isee-ai.cn/~zhwshi" target="_blank">Wei-Shi Zheng</a><sup>1,4&#8224</sup>,
              </span>
          </div>
          <!-- <br> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block">(* The work is done when Dian Zheng is an intern at Alibaba Group., &#8224 corresponding authors) </span>
        </div>

        <div class="is-size-5 publication-authors">
          <span class="author-block">
            <sup>1</sup>
            Sun Yat-sen University &nbsp;&nbsp;
            <sup>2</sup>
            Monash University &nbsp;&nbsp;
            <br>
            <sup>3</sup>
            Alibaba Group &nbsp;&nbsp;
            <sup>4</sup>
            Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China &nbsp;&nbsp;
          </span>
        </div>

        <div class="column has-text-centered">
          <div class="publication-links">
            
            <span class="link-block">
              <a href="https://arxiv.org/abs/2311.17982" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>Paper(PanoDecouple)</span>
              </a>
            </span>
            <!-- Code Link. -->
            <span class="link-block">
              <a href="https://github.com/iSEE-Laboratory/PanoDecouple" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>GitHub</span>
              </a>
            </span>
          </div>

        </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop" style="width: 50%; max-width: none;">
      <div class="hero-body">
            <img src="assets/vbench/images/teaser.jpg" style="width:100%; margin-bottom:10px" alt="Teaser."/>
      <p style="margin-top: 0;">
        <b>Overview of PanoDecouple.</b> PanoDecouple can achieve NFoV image outpainting with <b>terrific visual results</b>, <b>accurate distortion</b>, and <b>strong generalization ability</b>. We could also easily support two applications: 1) random NFoV input support by few step tuning (up). 2) text-to-panorama generation by utilizing a text-to-image model SDXL (bottom). Enjoy it!
      </p>
    </div>
  </div>
</section>

<!-- Abstract. -->
<section>
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered" style="margin-top: 10px; margin-bottom: 0px;">
      <div class="column is-four-fifths">
        <h2 class="title is-3 is-centered">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating 360-degree panoramas from narrow field of view (NFoV) images is a promising computer vision task for Virtual Reality (VR) applications. Existing methods mostly assess the generated panoramas with InceptionNet or CLIP-based metrics, which tend to perceive the image quality and are <b>not suitable for evaluating the distortion</b>.
            In this work, we first propose a distortion-specific CLIP, named Distort-CLIP, to accurately evaluate panorama distortion and discover the <b>"visual cheating"</b> phenomenon in previous works (i.e., tending to improve visual results by sacrificing distortion accuracy). This phenomenon arises because prior methods employ a single network to learn the distinct panorama distortion and content completion at once, which leads the model to prioritize optimizing the latter.
            To address this phenomenon, we propose <b>PanoDecouple</b>, a decoupled diffusion model framework, which decouples panorama generation into distortion guidance and content completion, aiming to generate panoramas with both accurate distortion and visual appeal. Specifically, we design a DistortNet for distortion guidance by imposing panorama-specific distortion priors and a modified condition registration mechanism; and a ContentNet for content completion by imposing perspective image information. Additionally, a distortion correction loss function with Distort-CLIP is introduced to constrain the distortion explicitly.
            Extensive experiments validate that <b>PanoDecouple</b> surpasses existing methods in both distortion and visual metrics.
          </p>
        </div>
      </div>
    </div>
</section>
<!--/ Abstract. -->

<section class="section" style="margin-top:-100px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="section-title">
          <h2 class="title is-3 is-centered">Visual cheating phenomenon in existing models</h2>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="assets/vbench/images/motivation_proj.jpg" style="width:1500px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p style="margin-top: 0;">
          The image quality and distortion accuracy of existing methods and ours by FID and Distort-FID (ours) respectively. We project two regions in panorama (signed in corresponding color) into perspective image to show the distortion accuracy of existing methods (i.e., no distortion and natural layout in perspective image means good results). Recent methods improve the image quality while significantly ruining the distortion. We named it <b>``visual cheating''</b> phenomenon.
        </p>
    </div>
  </div>
</section>


<section class="section" style="margin-top:-100px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="section-title">
          <h2 class="title is-3 is-centered">Tuning Pipeline of Distort-CLIP</h2>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="assets/vbench/images/clip.jpg" style="width:1500px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p style="margin-top: 0;">
          The training pipeline of our Distort-CLIP. The image features of three distortion types will perform cosine similarity with themselves, and with the text features of three distortion types respectively. ``-'' means that the corresponding elements will not participate in the computation because it is meaningless. The boxes in <span style="color:blue;">blue</span> mean the similarity of corresponding elements is 1, otherwise 0.
        </p>
        <!-- <p class="is-size-7" style="margin-top: 0;">
          The results are linearly normalized between 0 and 1 for better visibility across categories. -->
    </div>
  </div>
</section>


<section class="section" style="margin-top:-100px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="section-title">
          <h2 class="title is-3 is-centered">Training Pipeline of PanoDecouple</h2>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="assets/vbench/images/pipeline.jpg" style="width:1500px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p style="margin-top: 0;">
          The pipeline of the proposed PanoDecouple, a decoupled diffusion model. The <b>DistortNet</b> focuses on distortion guidance via the proposed distortion map. To make full use of the position-encoding-like distortion map, we modify the condition registration mechanism of ControlNet from the first block only to all the blocks. The <b>ContentNet</b> is devoted to content completion by imposing partial panorama image input and perspective information. The <b>U-Net</b> remains frozen, coordinating the information fusion between content completion and distortion guidance branches, while fully leveraging its powerful pre-trained knowledge. Note that we omit the text input of the DistortNet and U-Net for simplification, while the one for ContentNet is replaced by perspective image embedding.
        </p>
    </div>
  </div>
</section>


<section class="section" style="margin-top:-100px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="section-title">
          <h2 class="title is-3 is-centered">Comparison with existing methods</h2>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="assets/vbench/images/quality.jpg" style="width:1500px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p style="margin-top: 0;">
          Comparison with SOTA methods. <sup>†</sup> means re-implementing in our setting for fair comparison. Note that the bottom region of Laval is entirely black edges and we crop 20% of it when testing image quality and undo it when testing distortion as it requires the full image. <span style="color:gray;">(·)</span> means the crop setting of PanoDiff (crop 20% of the top and bottom regions). The best and second-best results are in <b>bold</b> and <u>underline</u>, respectively.
        </p>
    </div>
  </div>
</section>


<section class="section" style="margin-top:-100px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="section-title">
          <h2 class="title is-3 is-centered">Real-World NFoV Image Outpainting</h2>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="assets/vbench/images/supp.jpg" style="width:1500px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p style="margin-top: 0;">
          Visual results with raw image input. <b>Note that the images we use are for academic purposes only. If any copyright infringement occurs, we will promptly remove them.</b>
        </p>
    </div>
  </div>
</section>



<!-- BibTeX -->
<section class="hero is-light is-small" id="BibTeX" >
  <div class="container is-max-desktop content" style="margin-top: 40px; margin-bottom: 20px;">
    <h2 class="title">BibTeX</h2>
    <p>If you find our work useful, please consider citing our paper:</p>
    <pre><code>@InProceedings{zheng2025panorama,
      title={Panorama Generation From NFoV Image Done Right},
      author={Zheng, Dian and Zhang, Cheng and Wu, Xiao-Ming and Li, Cao and Lv, Chengfei and Hu, Jian-Fang and Zheng, Wei-Shi},
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
      year={2025}
}



<!-- footer -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://github.com/iSEE-Laboratory/iSEE-Laboratory.github.io/PanoDecouple/">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/iSEE-Laboratory/PanoDecouple" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>


