<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="OmniDexGrasp">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OmniDexGrasp</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <!-- Preload critical assets -->
  <link rel="preload" href="./ProPage/teaser/teaser-1.mp4" as="video" type="video/mp4">
  <link rel="preload" href="./static/images/setting.png" as="image">
  <link rel="preload" href="./static/images/method.png" as="image">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js" defer></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js" defer></script>
  <script src="./static/js/bulma-slider.min.js" defer></script>
  <script src="./static/js/index.js" defer></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span class="omni">Omni</span><span class="dex">Dex</span><span class="grasp">Grasp</span>: Generalizable Dexterous Grasping via Foundation Model and Force Feedback</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://wyl2077.github.io/">Yi-Lin Wei</a><sup>†</sup>,</span>
            <span class="author-block"><a href="https://zhexiluo.github.io/">Zhexi Luo</a><sup>†</sup>,</span>
            <span class="author-block">Yuhao Lin,</span>
            <span class="author-block"><a href="https://frenkielm.github.io/">Mu Lin</a>,</span>
            <span class="author-block">Zhizhao Liang,</span>
            <span class="author-block"><a href="https://github.com/Rain-Shuoyu">Shuoyu Chen</a>,</span>
            <span class="author-block"><a href="https://www.isee-ai.cn/~zhwshi/">Wei-Shi Zheng</a><sup>*</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Sun Yat-sen University</span>
          </div>
          <div class="is-size-6" style="margin-top: 8px;">
             <span class="author-block"><sup>†</sup>Equal contribution,</span>
             <span class="author-block" style="margin-left: 8px;"><sup>*</sup>Corresponding author</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2510.23119"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.23119"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/iSEE-Laboratory/OmniDexGrasp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <h2 class="title is-3 has-text-centered">Teaser</h2> -->
      <video id="teaser" autoplay muted loop playsinline style="width: 75%; display: block; margin: 0 auto;" controls preload="auto">
        <source src="./ProPage/teaser/teaser-1.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered">Overview</h2>
      <br>
      <h2 class="subtitle has-text-centered">
        <span class="omnidexgrasp">OmniDexGrasp</span> can achieve generalizable dexterous grasping with omni capabilities<br>in user prompting, dexterous embodiment, scenes, and grasping tasks, by leveraging<br>(1) foundation model, (2) human-image-to-robot-action transfer, (3) force-aware adaptive grasp.
      </h2>
      <img src="./static/images/setting.png" alt="OmniDexGrasp teaser image" style="width: 100%;" loading="eager"/>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered">Visualization</h2>
    </div>
  </div>
</section>
    <!-- New Demos Section -->
    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-multiline is-centered">

          <!-- Videos 1 & 2 -->
          <div class="column is-half">
            <div class="content has-text-centered">
              <video class="sequential-load" autoplay loop muted playsinline style="width: 100%;" preload="none">
                <source data-src="./ProPage/Semantic%20Grasp/Semantic%20Grasping.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <div class="column is-half">
            <div class="content has-text-centered">
              <video class="sequential-load" autoplay loop muted playsinline style="width: 100%;" preload="none">
                <source data-src="./ProPage/Cluttered%20Scenes/Cluttered%20Scenes-1.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <!-- Videos 3 & 4 -->
          <div class="column is-half">
            <div class="content has-text-centered">
              <video class="sequential-load" autoplay loop muted playsinline style="width: 100%;" preload="none">
                <source data-src="./ProPage/Human-Robot%20Handover/Human-Robot%20Handover-1.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <div class="column is-half">
            <div class="content has-text-centered">
              <video class="sequential-load" autoplay loop muted playsinline style="width: 100%;" preload="none">
                <source data-src="./ProPage/Fragile%20Object%20Grasping/Fragile%20Object%20Grasping-1.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <!-- Videos 5 & 6 -->
          <div class="column is-half">
            <div class="content has-text-centered">
              <video class="sequential-load" autoplay loop muted playsinline style="width: 100%;" preload="none">
                <source data-src="./ProPage/Cross-Embodiment/Cross-Embodiment-1.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <div class="column is-half">
            <div class="content has-text-centered">
              <video class="sequential-load" autoplay loop muted playsinline style="width: 100%;" preload="none">
                <source data-src="./ProPage/Grasp%20under%20Complex%20Lighting/Grasp%20under%20Complex%20Lighting-1.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <!-- Video 7 (Centered) -->
          <div class="column is-fullwidth">
            <div class="content has-text-centered is-flex is-justify-content-center">
              <div style="width: 50%;">
                <video class="sequential-load" autoplay loop muted playsinline style="width: 100%;" preload="none">
                  <source data-src="./ProPage/Extension%20to%20Manipulation/Extension%20to%20Manipulation-1.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
          
        </div>
      </div>
    </section>
    <!--/ New Demos Section -->

    <!-- Interactive Visualization -->
    <section class="section">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Interactive Visualization</h2>
        
        <div class="field">
          <div class="control">
            <div class="select is-rounded is-fullwidth">
              <select id="vis-select">
                <option value="" disabled selected>-- Select an Object --</option>
                <option value="watering-can">Watering Can</option>
                <option value="spray-bottle">Spray Bottle</option>
                <option value="3d-printed-object">3D Printed Object</option>
                <option value="electric-drill">Electric Drill</option>
                <option value="thermos-bottle">Thermos Bottle</option>
                <option value="mug">Mug</option>
                <option value="mineral-water-bottle">Mineral Water Bottle</option>
              </select>
            </div>
          </div>
        </div>

        <div class="columns is-vcentered has-text-centered" style="margin-top: 1rem;">
          <div class="column">
            <h3 class="title is-4">Generated Human Grasp</h3>
          </div>
          <div class="column">
            <h3 class="title is-4">Real World Grasping</h3>
          </div>
        </div>

        <div id="visualization-container">
          <!-- Item 1: Watering Can -->
          <div class="columns is-vcentered is-hidden" id="watering-can">
            <div class="column">
              <img data-src="./demo/Watering_can/gpt.png" alt="Generated grasp for Watering Can"/>
            </div>
            <div class="column">
              <iframe data-src="./demo/Watering_can/scene_dexhand_manohand_visualization.html" width="100%" height="400px" style="border:0;"></iframe>
            </div>
          </div>

          <!-- Item 2: Spray Bottle -->
          <div class="columns is-vcentered is-hidden" id="spray-bottle">
            <div class="column">
              <img data-src="./demo/Spray_Bottle/gpt.png" alt="Generated grasp for Spray Bottle"/>
            </div>
            <div class="column">
              <iframe data-src="./demo/Spray_Bottle/visualize/scene_dexhand_manohand_visualization.html" width="100%" height="400px" style="border:0;"></iframe>
            </div>
          </div>
          
          <!-- Item 3: 3D Printed Object -->
          <div class="columns is-vcentered is-hidden" id="3d-printed-object">
            <div class="column">
              <img data-src="./demo/3D_printed_object/gpt.png" alt="Generated grasp for 3D Printed Object"/>
            </div>
            <div class="column">
              <iframe data-src="./demo/3D_printed_object/visualize/scene_dexhand_manohand_visualization.html" width="100%" height="400px" style="border:0;"></iframe>
            </div>
          </div>

          <!-- Item 4: Electric Drill -->
          <div class="columns is-vcentered is-hidden" id="electric-drill">
            <div class="column">
              <img id="drill-img" data-src="./demo/Electric_Drill/gpt.png" alt="Generated grasp for Electric Drill"/>
            </div>
            <div class="column">
              <iframe id="drill-iframe" data-src="./demo/Electric_Drill/visualize/scene_dexhand_manohand_visualization.html" width="100%" height="400px" style="border:0;"></iframe>
            </div>
          </div>

          <!-- Item 5: Thermos Bottle -->
          <div class="columns is-vcentered is-hidden" id="thermos-bottle">
            <div class="column">
              <img data-src="./demo/Thermos_Bottle/gpt.png" alt="Generated grasp for Thermos Bottle"/>
            </div>
            <div class="column">
              <iframe data-src="./demo/Thermos_Bottle/visualize/scene_dexhand_manohand_visualization.html" width="100%" height="400px" style="border:0;"></iframe>
            </div>
          </div>

          <!-- Item 6: Mug -->
          <div class="columns is-vcentered is-hidden" id="mug">
            <div class="column">
              <img data-src="./demo/Mug/gpt.png" alt="Generated grasp for Mug"/>
            </div>
            <div class="column">
              <iframe data-src="./demo/Mug/visualize/scene_dexhand_manohand_visualization.html" width="100%" height="400px" style="border:0;"></iframe>
            </div>
          </div>
          
          <!-- Item 7: Mineral Water Bottle -->
          <div class="columns is-vcentered is-hidden" id="mineral-water-bottle">
            <div class="column">
              <img data-src="./demo/Mineral_water_bottle/gpt.png" alt="Generated grasp for Mineral Water Bottle"/>
            </div>
            <div class="column">
              <iframe data-src="./demo/Mineral_water_bottle/visualize/scene_dexhand_manohand_visualization.html" width="100%" height="400px" style="border:0;"></iframe>
            </div>
          </div>
        </div>

      </div>
    </section>
    <!--/ Interactive Visualization -->



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="abstract-panel">
          <div class="abstract-trigger" style="cursor: pointer;">
            <h2 class="title is-3">Abstract </h2>
          <br>
          </div>
          <div class="content has-text-justified" id="abstract-content">
            <p>
              In this work, we introduce <strong>OmniDexGrasp</strong>, a unified framework that achieves <em>generalizable dexterous grasping</em> solely guided by <strong>grasp demonstrations</strong> generated from <em>foundation generative models</em>. Without relying on robot data or additional training, OmniDexGrasp realizes <strong>omni-ability</strong> in functional grasping—covering six representative tasks, including semantic grasping, region/point grasping, grasping in cluttered scenes, one-shot demonstration grasping, human–robot handover, and fragile object grasping—while supporting multi-modal inputs such as language, visual prompts, and demonstration images.
            </p>
            <p>
              Unlike traditional methods that train a dedicated network to predict grasp poses, OmniDexGrasp leverages both a <strong>foundation generative model</strong> (e.g., GPT-Image) and a <strong>foundation visual model</strong> to synthesize human grasp images and convert them into executable dexterous robot actions. The framework integrates a <strong>human-image-to-robot-action</strong> transfer strategy that reconstructs and retargets generated human grasps to robot joint configurations, together with a <em>force-sensing adaptive grasping strategy</em> that ensures stable and reliable execution. Moreover, our framework is naturally extensible to manipulation tasks.
            </p>
            <p>
              Extensive experiments in both simulation and real-world settings demonstrate that foundation models can provide precise and semantically aligned guidance for dexterous grasping, achieving an average <strong>87.9%</strong> success rate across six diverse tasks. As foundation models continue to advance, we envision future work extending OmniDexGrasp toward non-prehensile manipulation, further promoting the integration of foundation models into embodied intelligence.
            </p>
          </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Framework -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Framework</h2>
        <div class="content has-text-centered">
          <img src="./static/images/method.png" alt="Framework of OmniDexGrasp" style="width: 100%;"/>
        </div>
        <div class="content has-text-justified">
          <p>
            (a) Using a <strong>foundation generative model</strong>, a human grasp image is generated based on the given grasp instruction and the initial scene image. (b) Relying solely on <strong>foundation visual models</strong>, the human-image-to-robot-action transfer module reconstructs the 3D hand–object interaction from the generated grasp image, retargets the human grasp to the robot’s dexterous hand, and aligns the grasp with the real-world object 6D pose to obtain an executable dexterous grasp action. (c) A <strong>force-sensing adaptive</strong> grasping strategy executes the grasp by dynamically adjusting finger motions according to force feedback, ensuring stable and reliable grasp execution.
          </p>
        </div>
      </div>
    </div>
    <!--/ Framework -->


    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{wei2025omnidexgrasp,
  author    = {Yi-Lin Wei and Zhexi Luo and Yuhao Lin and Mu Lin and Zhizhao Liang and Shuoyu Chen and Wei-Shi Zheng},
  title     = {OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback},
  journal   = {arXiv},
  year      = {2025},
}</code></pre>
      </div>
    </section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        The source code for this website is adapted from the template provided by <a href="https://github.com/nerfies/nerfies.github.io">nerfies.github.io</a>.
      </p>
    </div>
  </div>
</footer>

<script>
  document.addEventListener('DOMContentLoaded', () => {
    
    // --- Priority 4: Load remaining visualizations ---
    const loadOtherVisualizations = () => {
      const visualizationContainer = document.getElementById('visualization-container');
      // Select all lazy elements that are NOT the drill ones
      const lazyElements = Array.from(visualizationContainer.querySelectorAll('[data-src]:not(#drill-img):not(#drill-iframe)'));
      
      lazyElements.forEach(element => {
        element.setAttribute('src', element.getAttribute('data-src'));
        element.removeAttribute('data-src');
      });
    };

    // --- Priority 3: Load Drill Visualization ---
    const loadDrillVisualization = () => {
      const drillImg = document.getElementById('drill-img');
      const drillIframe = document.getElementById('drill-iframe');

      if (!drillImg || !drillIframe) {
        // Fallback in case elements are not found
        loadOtherVisualizations();
        return;
      }

      const imgPromise = new Promise(resolve => {
        drillImg.onload = resolve;
        drillImg.onerror = resolve; // Resolve on error too so it doesn't block the chain
        drillImg.setAttribute('src', drillImg.getAttribute('data-src'));
      });

      const iframePromise = new Promise(resolve => {
        drillIframe.onload = resolve;
        drillIframe.onerror = resolve;
        drillIframe.setAttribute('src', drillIframe.getAttribute('data-src'));
      });
      
      // After drill assets are loaded, load the rest
      Promise.all([imgPromise, iframePromise]).then(loadOtherVisualizations);
    };
    
    // --- Priority 2: Sequentially load demo videos ---
    const videos = Array.from(document.querySelectorAll('.sequential-load'));
    const loadVideo = (index) => {
      if (index >= videos.length) {
        // This case handles if there are no videos.
        // If there were videos, the chain is continued inside the 'canplay' listener.
        loadDrillVisualization();
        return;
      }
      
      const video = videos[index];
      const source = video.querySelector('source');
      const dataSrc = source.getAttribute('data-src');
      
      if (dataSrc) {
        source.setAttribute('src', dataSrc);
        video.load();
        
        // Define the next step in the chain
        const nextStep = () => {
          if (index === videos.length - 1) {
            // If this is the last video, start loading the drill visualization
            loadDrillVisualization();
          } else {
            // Otherwise, load the next video
            loadVideo(index + 1);
          }
        };

        video.addEventListener('canplay', nextStep, { once: true });
        // Add an error listener as a fallback
        video.addEventListener('error', nextStep, { once: true });

      } else {
        // If a video has no data-src, just move to the next one
        if (index === videos.length - 1) {
          loadDrillVisualization();
        } else {
          loadVideo(index + 1);
        }
      }
    };
    
    // Start the loading chain
    if (videos.length > 0) {
      loadVideo(0);
    } else {
      // If there are no videos to load, go straight to drill
      loadDrillVisualization();
    }
  });
</script>

</body>
</html>
